---
title: 'Blog Post 2: Is ChatGPT Making Us “Dumber” or Just Lazy Thinkers?'
date: 2025-09-21
permalink: /posts/2025/09/blog-post-2/
tags:
  - ai
  - education
  - cognition 
  - ethics
  - WSJ article 
  - technology
---

*The article warns that using AI too much can actually make our thinking skills weaker. To avoid this kind of “mental atrophy,” the authors suggest four simple habits: draft first (then prompt), use AI as a tutor, take timeouts/checklists, and schedule “AI-free” periods.*

**News Article:** 
[“How to Make Sure ChatGPT Doesn’t Make You Dumber” by Paul Rust & Nina Vasan, The Wall Street Journal (Sept 3, 2025)](https://www.wsj.com/tech/ai/chatgpt-tips-smarter-dc33a0fd?mod=ig_artificialintelligencereport)  


## The Article’s Argument: premises → conclusion

- **P1.** Humans have always looked for **shortcuts**, and now with AI we’re handing off even more — from writing and planning to analysis.
- **P2.** Early studies/surveys show heavy AI reliance correlates with **worse recall, lower performance without AI, and poorer critical thinking**.  
- **P3.** Over-trusting AI creates **automation bias**, so people import the model’s blind spots and stereotypes.  
- **P4.** Deliberate habits (draft-first, tutor mode, checklists, AI-free windows) **counter** those effects.  
- **C.** Therefore, we should **structure and limit** AI use to protect our core thinking skills.

## Fallacy / Weakness I See

**Hasty generalization (plus a weak analogy).**  
The piece moves from **small, context-specific evidence** (short studies, self-reports, aviation analogies) to a broad claim about long-term “cognitive atrophy.” Correlation ≠ causation; comparisons to manual skills don’t really fit knowledge work.

*Why it matters:* If **P2** is weaker than presented, **P1–P3** support *risk management*, not *inevitable decline*.

## Rebuttal: counter-argument

- **R1.** Well-designed offloading (like calculators, notes, or coding tools) has historically **helped performance** when the extra brain space is used for bigger picture thinking.
- **R2.** Learning research shows that ****practice, explaining, and reflecting**—all things AI can support—make understanding stronger.
- **R3.** Most of the harms the article points out are really **bad habits** (copying answers, not double checking), not problems with the tool itself.
- **R (Conclusion).** The article **overstates** the risk of decline; with good habits, AI can support or even boost our reasoning while cutting out busywork.

## Alternative Argument: independent

Even if AI can support deep learning, **institutions** optimize for visible productivity (tickets, docs) over skill formation.  
**C2.** Without things like AI training, no AI assessments, or assignments that actually require original thinking, personal good habits won’t be enough. Schools and workplaces need to set the default so that real thinking is valued, not just quick output.

## Recommendation - how to use the tech

1. **Manual first pass (10–20 min).** Outline bullets or a plan *before* opening an LLM.  
2. **Tutor mode > answer mode.** Prompt: *“Ask me questions and guide me; don’t give the final answer until I try.”*  
3. **2-minute verification checklist.** What’s the claim? Evidence? Missing perspectives? Bias? What can I verify quickly?  
4. **AI-free windows.** Schedule blocks or whole assignments, where AI is off.  
5. **Assessment without AI.** Use retrieval-based checkpoints (self-quizzes, oral explain-backs) to keep skills sharp.

## Reflection
This exercise made me think harder about how much we rely on AI. The scary version is that it could hollow out our minds, and honestly, that risk feels real if we lean on it too much. I see the value in habits like working manually first, using AI sparingly, and taking breaks from it altogether. For me, the point isn’t to squeeze the most out of AI but to make sure we don’t lose the ability to think on our own.