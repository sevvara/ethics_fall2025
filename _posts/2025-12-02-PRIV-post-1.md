---
title: 'PRIV Blog 1: When AI Meets Copyright'
date: 2025-12-02
permalink: /posts/2025/12/priv-blog-post-1/
tags:
  - ethics
  - technology
  - AI
  - copyright
  - generative-ai
---

*Reading the ARTificial case study made me reflect on what fairness, originality, and creativity mean in the age of generative AI. Here are my thoughts after sitting with the article, its questions, and how they connect to my own experiences.* 

**Case Study:** 
[ARTificial: Why Copyright Is Not the Right Policy Tool to Deal with Generative AI](https://yalelawjournal.org/forum/artificial-why-copyright-is-not-the-right-policy-tool-to-deal-with-generative-ai)

The article “ARTificial: Why Copyright Is Not the Right Policy Tool to Deal With Generative AI” looks at the messy relationship between generative AI and copyright law. As AI tools like DALL·E, Midjourney, and ChatGPT explode in popularity, they raise huge questions about originality, ownership, fairness, and what creativity even is in a world where machines can mimic it so well. The article tries to sort through those questions, and honestly, after reading it, I understand why this debate is so heated. 

## Why Compensation Still Feels Like the Heart of the Issue
One thing I always come back to is *fairness*. If AI models are trained on human-created works, shouldn’t those humans be compensated in some way? It feels wrong to me that artists contribute to datasets, often unknowingly, and benefit almost nothing from the outputs.

But the article makes a good point: **copyright law can’t meaningfully handle this**. AI doesn’t store images or text; it abstracts patterns from massive datasets. That’s not something you can trace back cleanly to an individual creator.

So while I think creators deserve compensation, I now understand it probably shouldn’t happen through copyright alone. We need new systems, training licenses, creator opt-ins, revenue sharing, something more realistic and less legally impossible.

## Where Fair Use Meets the Reality of AI Training
Before reading this, I thought training models on copyrighted work was obviously “infringement.” But the more I understood how AI actually learns, the more I realized it’s not that simple.

A model learning patterns is not the same as a model copying files.

Legally, **AI training might count as fair use** because it’s highly transformative, similar to the Google Books case the article references. But ethically, it still feels messy. Just because something is *legal*, doesn’t make it *right*.

I’m now sitting somewhere in the middle:  
- The training itself may be fair use,  
- But creators still deserve consent and transparency.

## Thinking About Originality in the Age of AI
This is where my mind went in circles. Are AI outputs “derivative”? Are they original? Are they… something in between?

The article helped me see that the answer isn’t binary. Some AI outputs imitate styles so closely that they feel derivative. Others are wildly new or unexpected. The math behind the training doesn’t support the idea that an output is simply a collage or copy, even if it sometimes *looks* that way.

My personal view:  
Some AI works are clearly derivative in an artistic sense, even if they’re not derivative in a *legal* sense.

## Why I Don’t Think AI Outputs Should Be Copyrighted
This feels simple to me: AI isn’t conscious. It doesn’t feel inspiration, frustration, excitement, or curiosity. It doesn’t have memories or experiences.

Copyright is supposed to reward human effort, skill, intention.

Giving copyright to AI outputs feels like rewarding a machine for doing exactly what it was programmed to do. It also risks overwhelming the public domain with AI-generated material, which could hurt human creators long-term.

So I stand with the article: **AI outputs should not receive copyright protection.**

## Drawing the Line Between Using AI as a Tool vs. Letting It Create
This is relevant for me personally, since I use AI regularly. I see a clear difference between:

- using AI to brainstorm, draft, edit, or support my creative work,  
and  
- letting AI fully generate something on its own.

If I shape, revise, interpret, and inject my own judgment into the output, that feels like authorship. If I click one button and paste what the model gives me, that doesn’t.

The law isn’t ready to draw this line cleanly, but I think eventually it will have to.

## Should AI Art Be Treated Like Human Art? My Thoughts
Even if a model produces something indistinguishable from human art, I don’t think we should treat them the same.

Human art comes from lived experience, culture, emotion, struggle, memory. AI has none of that. That doesn’t mean AI art has zero value, but it’s fundamentally different. And pretending they’re identical feels like ignoring what makes creativity *human* in the first place.

## A Question We Should All Be Asking
**If copyright isn’t the right tool, what *new* framework could realistically support artists without slowing innovation?**

This question matters because it pushes us beyond “complaining about AI” toward imagining actual solutions. The article critiques copyright well, but doesn’t offer a full alternative. And I think the future depends on finding one.

## Reflecting 
I honestly walked away from this case study both more informed and more uncertain, and that’s a good thing. It made me confront assumptions I didn’t realize I had. I learned how different the technical reality is from the moral panic online. At the same time, I still feel strongly about protecting human creators.

Tech ethics always lives in the gray areas, and this exercise reminded me how important it is to sit with that uncertainty and keep asking questions.
