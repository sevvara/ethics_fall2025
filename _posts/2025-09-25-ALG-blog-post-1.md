---
title: 'ALG Blog Post 1: Exception to Data Driven Rules'
date: 2025-09-25
permalink: /posts/2025/09/ALG-blog-post-1/
tags:
  - Ethics
  - Uncertainty 
  - Individualization
  - Exceptions
  - Data-driven Rules
---

*Exploring when strict data-driven rules fall short, and why exceptions matter for fairness.* 

**Case Study:** 
["The Right to Be an Exception to a Data‑Driven Rule" by Sarah H. Cen and Manish Raghavan](https://mit-serc.pubpub.org/pub/right-to-be-exception/release/2)  


## When Algorithms Forget We’re Human: The Problem with Perfect Rules
I’ve been thinking about how often algorithms make decisions for us, from the credit score that decides if you get a loan to the resume filters that judge candidates before a human ever looks. These systems promise efficiency, but they often forget something essential: people are messy, unpredictable, and wonderfully inconsistent.

I read “The Right to Be an Exception to a Data-Driven Rule” by Sarah H. Cen and Manish Raghavan, and it hit me that being an “exception” isn’t about breaking rules, it’s about recognizing when data-driven systems don’t tell the whole story. Sometimes, life doesn’t fit into a spreadsheet.

## When Data Misses the Details
Take credit scores. If a rule says “deny the loan if the score is below 650,” it sounds logical. But what if someone’s score dropped because of medical bills they’ve already paid off? The algorithm can’t see that context, it just sees numbers. Humans, for all our flaws, can recognize that a person isn’t an error in the system, the system simply isn’t flexible enough. Humans bring empathy and instinct. Algorithms bring consistency but rigidity. It’s like the difference between GPS directions and advice from a friend. The GPS might be technically correct, but your friend might warn you about a flooded road,  or show you a prettier route.

Fairness sits somewhere between rule and exception. Individualization makes systems feel humane, but too many exceptions can look like favoritism. If rules never bend, though, the world starts to feel cold. The challenge is balance, rigid enough to keep order, flexible enough to stay human.

## Why Uncertainty Matters
What really stood out to me was how uncertainty plays into fairness. No dataset can perfectly capture a person’s life, yet we treat algorithmic accuracy as sacred. A 90% accuracy rate sounds great until you remember that the 10% left behind are real people. Exceptions give space for doubt, a moment to ask, What if this case is one of the outliers?

## The Question I Keep Asking
That made me wonder: **How should individuals be empowered to contest data-driven decisions that negatively affect them?**
If algorithms continue shaping our opportunities, there should be a way to say, “Wait, I’m not just data.” Whether through transparency rules, advocacy groups, or audit tools, people deserve the right to challenge an algorithmic judgment and demand a human look.

## My Takeaway
Reading this case study made me more aware of the hidden costs of convenience. Algorithms make life smoother, but they risk turning people into probabilities. As someone who benefits from recommendation systems every day, I rarely think about those they fail.
This study reminded me that fairness isn’t only about getting the math right, it’s about remembering the human behind the data. Because even in a data-driven world, we deserve the right to be human. 
