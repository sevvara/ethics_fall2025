---
title: "Case study"
layout: single 

collection: casestudy
permalink: /casestudy/
author_profile: true
share: false 
layout: default
#nav_order: 0
---

**When “Accept All” Means Everything: How Cookie Consent Normalizes Data Surveillance**

Every time users click **“Accept All”** on a cookie banner, they participate in one of the largest invisible data-collection systems online. While cookies were originally meant to improve user experience, they now fuel cross-site tracking, advertising, and behavioral profiling. This case study explores why meaningful consent rarely exists, how companies design banners to nudge users, and what happens to data once it begins circulating across the web.

# Navigation  
Choose a section to explore:

- **[Background: How Cookie Tracking Works](background/)**  
- **[Ethical Problem: The Illusion of Consent](#ethical-problem-draft)**  
- **[Stakeholder Overview](stakeholders/)**  
- **[Interactive Activity](activity/)**  
- **Audience Pages:**  
  - [Internet Users](audience-users/)  
  - [Tech Designers & Companies](audience-tech/)  
  - [Policy Makers & Regulators](audience-policy/)  
- **[Discussion Questions](#discussion-questions-draft)**  
- **[Works Cited](workscited/)**  

# Ethical Problem (Draft)

Ethical Problem (Draft)
Cookies sit at the intersection of user autonomy, corporate incentives, and governance. Although users are “asked” to consent, decades of research in behavioral economics and human-computer interaction suggests that this consent is neither informed nor free.
**Why Most Users Click “Accept All”**
Several factors converge:
- Cognitive fatigue — Banners appear constantly; users want to browse, not negotiate permissions.
- UI pressure — The path of least resistance (one click) overwhelmingly leads to tracking.
- Information asymmetry — Users do not understand what cookies actually do.
- Transfer of risk — Users bear the privacy risk; companies capture the financial upside.
This dynamic mirrors what legal theorists call “structural consent failure”: a system designed to create the appearance of choice without offering meaningful alternatives (Richards & Hartzog, 2021).
 [Link:] (https://academic.oup.com/jla/article/13/1/43/6180579)

## How Dark Patterns Shape the Choice
Dark patterns aren’t merely annoying — they are forms of digital coercion. Regulators have begun identifying them as unethical or unlawful because they exploit cognitive biases such as:
- Default bias — users stick with whatever is easiest
- Framing effects — positive language around acceptance
- Friction asymmetry — declining requires many steps; accepting requires one
Furman et al. (2022) show that users are far more likely to accept cookies when banners use color and placement to highlight the “Accept All” button.

[Link:] (https://www.sciencedirect.com/science/article/pii/S0167811623000708)

These techniques undermine the principle of informed consent and create a situation where behavioral manipulation is normalized.

## Imbalance of Knowledge and Power
Tech companies understand tracking technologies deeply and profit from them. Users, by contrast, see only a brief pop-up with vague wording. This information imbalance generates an ethical problem similar to the power asymmetries discussed in business-ethics literature (Crane & Matten, 2004).
[Link:] (https://link.springer.com/article/10.1007/s10551-005-1421-8)
Companies design the system; users navigate it.
- Who benefits?
- Who bears the risk?
- Whose autonomy is being reduced?
These questions illustrate why the cookie consent ecosystem is closer to surveillance by default than genuine user empowerment.


# Stakeholders (Draft)

This section will outline the motivations and concerns of:  
- Internet users  
- Tech companies  
- Advertisers  
- Regulators  

**Internet Users**
Users want:
- privacy
- agency
- easy-to-use websites
- protection from exploitation

But they face:
- confusing banners
- power asymmetries
- lack of transparency
- fatigue from repeated consent decisions
The average user has neither the time nor the expertise to evaluate dozens of trackers per day.

**Tech Companies**
Tech companies benefit from data collection and personalization. They often justify tracking by emphasizing:
personalization:

- “free” services supported by ads
- efficiency of targeted advertising
But profit incentives push them to implement dark patterns, minimize transparency, and maximize acceptance rates. Data fuels recommendation systems, advertising algorithms, and behavioral analytics — a competitive advantage (Aalto doctoral thesis on tracking ecosystems).
[Link:] (https://aaltodoc.aalto.fi/items/930fa379-af73-4954-a518-872c848b5273)

**Advertisers**
Advertisers rely on:
- detailed user profiles
- cross-site tracking
- algorithmic bidding markets
- behavioral prediction

Without cookies, targeted advertising becomes less precise. Stakeholder research shows advertisers fear “signal loss” and declining ROI as privacy restrictions increase.

**Regulators**
Regulators aim to protect users while allowing digital markets to function. But enforcement remains difficult:
Dark patterns evolve faster than law

- Cross-border enforcement is complicated
- Many websites do the bare minimum for compliance
Studies highlight limited compliance with GDPR even years after implementation (Santos et al., 2022).
[Link:] (https://dl.acm.org/doi/abs/10.1145/3564625.3564647)
Regulators are therefore both necessary stakeholders and reactive participants in a rapidly 


# Interactive Activity Preview (Draft)

This project includes an interactive test that measures **how fast you react to cookie banners**.  
Users will respond to randomized “Accept All / Manage Preferences” pop-ups, and the system will track:

- reaction time  
- whether you accepted “good” or “bad” cookies  
- behavioral patterns  

The activity will appear on the **Interactive Activity** page.

# Discussion Questions (Draft)

1. Is informed consent possible when people click automatically?  
2. Should laws require “Reject All” to be as visible as “Accept All”?  
3. Who should be responsible for preventing dark patterns?  
4. Do users have real control over how their data circulates?  
5. How can transparency be improved?  

# Works Cited (Draft)

See the **[Works Cited](workscited/)** page for sources.
